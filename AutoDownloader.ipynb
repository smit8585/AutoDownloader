{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoDownloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 : Complete code of working AutoDownloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from bs4 import BeautifulSoup as bs #for web scraping \n",
    "import requests  # to access webpage\n",
    "import pandas as pd # to store data into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing data required to make list of urls \n",
    "alphabets = list(map(chr,range(97,123))) # [chr(i) for i in range(97,123)]          \n",
    "npages = [88,22,40,28,209,121,419,63,4,7,11,24,95,174,9,16,0,63,176,8,36,17,4,0,3,0]\n",
    "#each page contains 20 data items \n",
    "nos = []\n",
    "for i in npages:\n",
    "    if i%20==0:\n",
    "        nos.append(i//20)\n",
    "    else:\n",
    "        nos.append((i//20)+ 1)\n",
    "\n",
    "#npages\n",
    "#alphabets\n",
    "#nos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing list of urls to access multiple pages \n",
    "urls = []\n",
    "for alphabet,no in zip(alphabets,nos):\n",
    "    for n in range(no):\n",
    "        urls.append(f\"http://airfoiltools.com/search/list?page={alphabet}&no={n}\")\n",
    "#urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading airfoils names from csv \n",
    "# Code for preparing dataset of airfoil names are available in the section2\n",
    "df = pd.read_csv(\"Airfoil_names.csv\")\n",
    "#df.head(3)\n",
    "airfoil_names = list(df['AirfoilName']) \n",
    "#len(foil_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of required Rynolds numbers\n",
    "Rnumbers = [50000,100000,200000,500000,1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing list of urls of datasets\n",
    "csv_urls = []\n",
    "for name in airfoil_names:\n",
    "    for Rnumber in Rnumbers:\n",
    "        csv_urls.append(f\"http://airfoiltools.com/polar/csv?polar=xf-{name}-{Rnumber}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Downloading datasets from each urls \n",
    "\n",
    "# # Note: It takes a lot of time to do the work\n",
    "# # Only use this code if datasets are not available locally on machine\n",
    "\n",
    "# import webbrowser \n",
    "# import time\n",
    "\n",
    "# for url in csv_urls:\n",
    "#     webbrowser.open(url)\n",
    "#     time.sleep(3)  # time = number of iterations * sleep time\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 : Preparing dataset of Airfoil names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Note : it takes few minutes to do web scraping\n",
    "# # only use this code when airfoil names are not available \n",
    "\n",
    "# airfoil_names = [] # to hold each names\n",
    "# for url in urls:\n",
    "#     page = requests.get(url)  # accessing webpage\n",
    "#     soup = bs(page.content)  # reading pure html \n",
    "    \n",
    "#     fullnames = [ i.text for i in soup.find_all(class_='cell12')]  # scraping required data\n",
    "#     fnames = [fullname.split()[0] for fullname in fullnames]  # filtering required data\n",
    "#     names = [fname[1:-1] for fname in fnames]  \n",
    "#     airfoil_names.extend(names)  # making list of airfoil names\n",
    "     \n",
    "#     page.close()  #explicitly closing webpage to prevent DoS attack due to large number of requests\n",
    "    \n",
    "# #airfoil_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # preparing csv file from the list of scraped airfoil names\n",
    "\n",
    "# df = pd.DataFrame()\n",
    "# df[\"AirfoilName\"] = airfoil_names  \n",
    "# df.to_csv(\"namestest.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some helping code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urls which will not work as their datasets are not available at this urls\n",
    "unavail_csv_urls = ['http://airfoiltools.com/polar/csv?polar=xf-ah85l120-il-200000','http://airfoiltools.com/polar/csv?polar=xf-fx79w470a-il-50000','http://airfoiltools.com/polar/csv?polar=xf-fx79w470a-il-100000','http://airfoiltools.com/polar/csv?polar=xf-fx79w470a-il-200000','http://airfoiltools.com/polar/csv?polar=xf-fx79w470a-il-500000','http://airfoiltools.com/polar/csv?polar=xf-fx79w470a-il-1000000','http://airfoiltools.com/polar/csv?polar=xf-goe451-il-1000000','http://airfoiltools.com/polar/csv?polar=xf-hs1404-il-100000','http://airfoiltools.com/polar/csv?polar=xf-naca0006-il-500000','http://airfoiltools.com/polar/csv?polar=xf-sp4621hp-po-50000','http://airfoiltools.com/polar/csv?polar=xf-sp4621hp-po-100000','http://airfoiltools.com/polar/csv?polar=xf-sp4721la-po-50000','http://airfoiltools.com/polar/csv?polar=xf-sp4721la-po-100000']\n",
    "#unavail_csv_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to skip some datasets \n",
    "# # Note : only use this shit if datasets are not available locally on machine\n",
    "\n",
    "# import webbrowser \n",
    "# import time\n",
    "\n",
    "# for url in csv_urls:\n",
    "#     if url in unavail_csv_urls:\n",
    "#         continue\n",
    "#     webbrowser.open(url)\n",
    "#     time.sleep(3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 88\n",
      "b 22\n",
      "c 40\n",
      "d 28\n",
      "e 209\n",
      "f 121\n",
      "g 419\n",
      "h 63\n",
      "i 4\n",
      "j 7\n",
      "k 11\n",
      "l 24\n",
      "m 95\n",
      "n 174\n",
      "o 9\n",
      "p 16\n",
      "q 0\n",
      "r 63\n",
      "s 176\n",
      "t 8\n",
      "u 36\n",
      "v 17\n",
      "w 4\n",
      "x 0\n",
      "y 3\n",
      "z 0\n"
     ]
    }
   ],
   "source": [
    "#to cross check the count of Airfoils against the counts showing on website\n",
    "count = 0\n",
    "for alphabet in alphabets:\n",
    "    for name in airfoil_names:\n",
    "        if name.startswith(alphabet):\n",
    "            count = count+1\n",
    "    print(alphabet,count)\n",
    "    count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
